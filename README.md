CS 5890 - Hidden Markov Models
================================

    Ross Nordstrom
    University of Colorado - Colorado Springs
    CS 5890 - Computational Linguistics

## Assignment

1. (By hand) Design an HMM for POS tagging on a provided dataset, including a drawing of the HMM structure.
2. Use supervised learning -- with a random 90% of the labeled dataset -- to obtain the probabilities needed for the HMM.
3. Using the learned paramter values, label the remaining 10% of the sentences using the Viterbi algo and the given POS tags.  Implement the Viterbi algo yourself.  Report precision (how many labels are correct).  Repeat #2 and #3 a few times and report average results.
4. _Extra Credit:_ Use expectation maximization to learn the parameters using the unlabeled dataset. Compute precision as done in #3.

## Dataset
Data was generated by Professor Kalita and the class.

## Usage
This project is intended to be used via the CLI.

```sh
npm install
npm link

rdnHmm --help
```

### Testing
```sh
npm install
npm test
```

### Results

Example results after 10,000 iterations on the "Full" Dataset

```sh
$ time rdnhmm -q -n 10000
Results from 10000 iterations of the HMM:

Sentence Precisions (freq by val): {
  "1": 152,
  "0.9": 877,
  "0.8": 1964,
  "0.7": 2684,
  "0.6": 2311,
  "0.5": 1307,
  "0.4": 521,
  "0.3": 157,
  "0.2": 25,
  "0.1": 2
}

Mean: 0.67,  Min: 0.10,  Max: 1.00

Tag Precisions (freq by val): {
  "1": 187,
  "0.95": 810,
  "0.9": 2068,
  "0.85": 1654,
  "0.8": 1516,
  "0.75": 1393,
  "0.7": 926,
  "0.65": 661,
  "0.6": 367,
  "0.55": 234,
  "0.5": 105,
  "0.45": 47,
  "0.4": 23,
  "0.35": 6,
  "0.3": 1,
  "0.25": 1,
  "0.2": 1
}

Mean: 0.80,  Min: 0.20,  Max: 1.00

real	0m34.019s
user	0m34.090s
sys 	0m0.080s
```
