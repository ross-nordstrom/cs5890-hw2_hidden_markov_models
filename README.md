CS 5890 - Hidden Markov Models
================================

    Ross Nordstrom
    University of Colorado - Colorado Springs
    CS 5890 - Computational Linguistics

## Assignment

1. (By hand) Design an HMM for POS tagging on a provided dataset, including a drawing of the HMM structure.
2. Use supervised learning -- with a random 90% of the labeled dataset -- to obtain the probabilities needed for the HMM.
3. Using the learned paramter values, label the remaining 10% of the sentences using the Viterbi algo and the given POS tags.  Implement the Viterbi algo yourself.  Report precision (how many labels are correct).  Repeat #2 and #3 a few times and report average results.
4. _Extra Credit:_ Use expectation maximization to learn the parameters using the unlabeled dataset. Compute precision as done in #3.

## Dataset
Data was generated by Professor Kalita and the class.

## Usage
This project is intended to be used via the CLI.

```sh
npm install
npm link

rdnHmm --help
```

### Testing
```sh
npm install
npm test
```

### Results

Example results after 10,000 iterations on the "Full" Dataset

```sh
$ time rdnhmm -q -n 10000
Results from 10000 iterations of the HMM:

Sentence Precisions (freq by val): {
  "1": 175,
  "0.9": 888,
  "0.8": 1961,
  "0.7": 2671,
  "0.6": 2247,
  "0.5": 1349,
  "0.4": 539,
  "0.3": 145,
  "0.2": 22,
  "0.1": 3
}

Mean: 0.67,  Min: 0.10,  Max: 1.00

Tag Precisions (freq by val): {
  "1": 199,
  "0.97": 9,
  "0.96": 616,
  "0.95": 82,
  "0.94": 1,
  "0.93": 152,
  "0.92": 667,
  "0.91": 335,
  "0.9": 1004,
  "0.85": 1675,
  "0.8": 1534,
  "0.75": 1380,
  "0.7": 888,
  "0.65": 692,
  "0.6": 500,
  "0.5": 211,
  "0.4": 48,
  "0.3": 5,
  "0.2": 1,
  "0.1": 1
}

Mean: 0.80,  Min: 0.14,  Max: 1.00

real	0m35.537s
user	0m35.390s
sys 	0m0.148s
```
